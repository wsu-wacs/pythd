{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import igraph\n",
    "\n",
    "import umap\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN, OPTICS\n",
    "\n",
    "import pythd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CUR_DIR = Path.cwd()\n",
    "DATA_DIR = CUR_DIR.parent / 'data'\n",
    "\n",
    "HELOC_NAME = 'heloc_dataset_v1.csv'\n",
    "HELOC_PATH = DATA_DIR / HELOC_NAME\n",
    "CLUSTER_METHODS = ['complete', 'average']\n",
    "\n",
    "METRIC='euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(HELOC_PATH, dtype={'RiskPerformance': 'category'})\n",
    "df['MaxDelq2PublicRecLast12M'] = df['MaxDelq2PublicRecLast12M'].map({\n",
    "    0: 0,\n",
    "    1: 120,\n",
    "    2: 90,\n",
    "    3: 60,\n",
    "    4: 30,\n",
    "    5: 0,\n",
    "    6: 0,\n",
    "    7: 0,\n",
    "    8: 0,\n",
    "    9: 0\n",
    "})\n",
    "\n",
    "df['MaxDelqEver'] = df['MaxDelqEver'].map({\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 120,\n",
    "    4: 90,\n",
    "    5: 60,\n",
    "    6: 30,\n",
    "    7: 0,\n",
    "    8: 0,\n",
    "    9: 0\n",
    "})\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(columns=['RiskPerformance', 'ExternalRiskEstimate']).values.astype(np.float32)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = df['RiskPerformance'].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_mats = {\n",
    "    method: linkage(X, method=method, metric=METRIC)\n",
    "    for method in CLUSTER_METHODS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = pythd.filter.ScikitLearnFilter(umap.UMAP, n_components=2, n_neighbors=9, min_dist=0.01, metric=METRIC)\n",
    "f_x = filt(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-tuesday",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(pythd)\n",
    "reload(pythd.clustering)\n",
    "reload(pythd.mapper)\n",
    "reload(pythd.thd)\n",
    "\n",
    "cov = pythd.cover.IntervalCover.EvenlySpacedFromValues(f_x, 200, 0.5)\n",
    "clustering = pythd.clustering.HierarchicalClustering(method='complete', metric='precomputed')\n",
    "#clustering = pythd.clustering.ScikitLearnClustering(OPTICS, min_samples=2, n_jobs=1, max_eps=100.0, metric='precomputed')\n",
    "#clustering = pythd.clustering.ScikitLearnClustering(DBSCAN, n_jobs=1, metric='precomputed')\n",
    "thd = pythd.thd.THD(X, filt, cov, full_df=X, clustering=clustering, \n",
    "                    group_threshold=2, contract_amount=0.1, \n",
    "                    precompute=True, metric=METRIC)\n",
    "\n",
    "old_settings = np.seterr(divide='ignore', invalid='ignore')\n",
    "groups = thd.run(verbose=True)\n",
    "_ = np.seterr(**old_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = groups.as_igraph_graph()\n",
    "\n",
    "vs = {\n",
    "    \"margin\": 40,\n",
    "    \"bbox\": (700, 300),\n",
    "    #\"vertex_label\": g.vs[\"name\"],\n",
    "    \"vertex_label_size\": 10,\n",
    "    \"vertex_size\": 5,\n",
    "    \"vertex_label_dist\": 1.5,\n",
    "    \"vertex_label_angle\": 0,\n",
    "    \"layout\": g.layout_reingold_tilford(root=[0])\n",
    "}\n",
    "\n",
    "igraph.plot(g, **vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cut_params(method):\n",
    "    return {\n",
    "        'combine_method': 'max',\n",
    "        'cluster_method': method,\n",
    "        'metric': METRIC\n",
    "    }\n",
    "\n",
    "g = None\n",
    "max_dist = max(map(lambda Z: Z[-1, 2], Z_mats.values()))\n",
    "dists = np.linspace(0.0, max_dist, num=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_labels = {\n",
    "    name: [fcluster(Z, t=dist, criterion='distance') for dist in dists]\n",
    "    for name, Z in Z_mats.items()\n",
    "}\n",
    "\n",
    "thd_labels = {\n",
    "    name: [groups.cut_on_distance(dist, **make_cut_params(name))[1] for dist in dists]\n",
    "    for name in CLUSTER_METHODS\n",
    "}\n",
    "\n",
    "for name, labels in hc_labels.items():\n",
    "    plt.semilogy(dists, [len(np.unique(y_pred)) for y_pred in labels], label=name)\n",
    "for name, labels in thd_labels.items():\n",
    "    plt.semilogy(dists, [len(np.unique(y_pred))-1 for y_pred in labels], label='thd ({})'.format(name))\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"distance\")\n",
    "plt.ylabel(\"num. clusters\")\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_ami = {\n",
    "    name: np.array([metrics.adjusted_mutual_info_score(y, y_pred) for y_pred in labels])\n",
    "    for name, labels in hc_labels.items()\n",
    "}\n",
    "\n",
    "thd_ami = {\n",
    "    name: np.array([metrics.adjusted_mutual_info_score(y, y_pred) for y_pred in labels])\n",
    "    for name, labels in thd_labels.items()\n",
    "}\n",
    "\n",
    "for name, values in hc_ami.items():\n",
    "    plt.plot(dists, values, label=name)\n",
    "for name, values in thd_ami.items():\n",
    "    plt.plot(dists, values, label='thd ({})'.format(name))\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Adjusted Mutual Information\")\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_ars = {\n",
    "    name: np.array([metrics.adjusted_rand_score(y, y_pred) for y_pred in labels])\n",
    "    for name, labels in hc_labels.items()\n",
    "}\n",
    "\n",
    "thd_ars = {\n",
    "    name: np.array([metrics.adjusted_rand_score(y, y_pred) for y_pred in labels])\n",
    "    for name, labels in thd_labels.items()\n",
    "}\n",
    "\n",
    "for name, values in hc_ars.items():\n",
    "    plt.plot(dists, values, label=name)\n",
    "for name, values in thd_ars.items():\n",
    "    plt.plot(dists, values, label='thd ({})'.format(name))\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Adjusted Rand Score\")\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise = metrics.pairwise_distances(X, metric=METRIC)\n",
    "            \n",
    "hc_sil = {\n",
    "    name: np.array([metrics.silhouette_score(pairwise, y_pred, metric='precomputed') for y_pred in labels\n",
    "                    if np.unique(y_pred).shape[0] > 1])\n",
    "    for name, labels in hc_labels.items()\n",
    "}\n",
    "\n",
    "thd_sil = {\n",
    "    name: np.array([metrics.silhouette_score(pairwise, y_pred, metric='precomputed') for y_pred in labels\n",
    "                    if np.unique(y_pred).shape[0] > 1])\n",
    "    for name, labels in thd_labels.items()\n",
    "}\n",
    "\n",
    "for name, values in hc_sil.items():\n",
    "    n = values.shape[0]\n",
    "    plt.plot(dists[:n], values, label=name)\n",
    "for name, values in thd_sil.items():\n",
    "    n = values.shape[0]\n",
    "    plt.plot(dists[:n], values, label='thd ({})'.format(name))\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Silhouette Score')\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-premiere",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
